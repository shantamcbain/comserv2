.\" -*- mode: troff; coding: utf-8 -*-
.\" Automatically generated by Pod::Man 5.01 (Pod::Simple 3.43)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" \*(C` and \*(C' are quotes in nroff, nothing in troff, for use with C<>.
.ie n \{\
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{\
.    if \nF \{\
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{\
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\" ========================================================================
.\"
.IX Title "DBIx::Class::Fixtures 3pm"
.TH DBIx::Class::Fixtures 3pm 2017-09-25 "perl v5.38.2" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH NAME
DBIx::Class::Fixtures \- Dump data and repopulate a database using rules
.SH SYNOPSIS
.IX Header "SYNOPSIS"
.Vb 1
\& use DBIx::Class::Fixtures;
\&
\& ...
\&
\& my $fixtures = DBIx::Class::Fixtures\->new({
\&     config_dir => \*(Aq/home/me/app/fixture_configs\*(Aq
\& });
\&
\& $fixtures\->dump({
\&   config => \*(Aqset_config.json\*(Aq,
\&   schema => $source_dbic_schema,
\&   directory => \*(Aq/home/me/app/fixtures\*(Aq
\& });
\&
\& $fixtures\->populate({
\&   directory => \*(Aq/home/me/app/fixtures\*(Aq,
\&   ddl => \*(Aq/home/me/app/sql/ddl.sql\*(Aq,
\&   connection_details => [\*(Aqdbi:mysql:dbname=app_dev\*(Aq, \*(Aqme\*(Aq, \*(Aqpassword\*(Aq],
\&   post_ddl => \*(Aq/home/me/app/sql/post_ddl.sql\*(Aq,
\& });
.Ve
.SH DESCRIPTION
.IX Header "DESCRIPTION"
Dump fixtures from source database to filesystem then import to another
database (with same schema) at any time. Use as a constant dataset for running
tests against or for populating development databases when impractical to use
production clones. Describe fixture set using relations and conditions based on
your DBIx::Class schema.
.SH "DEFINE YOUR FIXTURE SET"
.IX Header "DEFINE YOUR FIXTURE SET"
Fixture sets are currently defined in .json files which must reside in your
config_dir (e.g. /home/me/app/fixture_configs/a_fixture_set.json). They
describe which data to pull and dump from the source database.
.PP
For example:
.PP
.Vb 10
\& {
\&   "sets": [
\&     {
\&       "class": "Artist",
\&       "ids": ["1", "3"]
\&     },
\&     {
\&       "class": "Producer",
\&       "ids": ["5"],
\&       "fetch": [
\&         {
\&           "rel": "artists",
\&           "quantity": "2"
\&         }
\&       ]
\&     }
\&   ]
\& }
.Ve
.PP
This will fetch artists with primary keys 1 and 3, the producer with primary
key 5 and two of producer 5's artists where 'artists' is a has_many DBIx::Class
rel from Producer to Artist.
.PP
The top level attributes are as follows:
.SS sets
.IX Subsection "sets"
Sets must be an array of hashes, as in the example given above. Each set
defines a set of objects to be included in the fixtures. For details on valid
set attributes see "SET ATTRIBUTES" below.
.SS rules
.IX Subsection "rules"
Rules place general conditions on classes. For example if whenever an artist
was dumped you also wanted all of their cds dumped too, then you could use a
rule to specify this. For example:
.PP
.Vb 10
\& {
\&   "sets": [
\&     {
\&       "class": "Artist",
\&       "ids": ["1", "3"]
\&     },
\&     {
\&       "class": "Producer",
\&       "ids": ["5"],
\&       "fetch": [
\&         {
\&           "rel": "artists",
\&           "quantity": "2"
\&         }
\&       ]
\&     }
\&   ],
\&   "rules": {
\&     "Artist": {
\&       "fetch": [ {
\&         "rel": "cds",
\&         "quantity": "all"
\&       } ]
\&     }
\&   }
\& }
.Ve
.PP
In this case all the cds of artists 1, 3 and all producer 5's artists will be
dumped as well. Note that 'cds' is a has_many DBIx::Class relation from Artist
to CD. This is eqivalent to:
.PP
.Vb 10
\& {
\&   "sets": [
\&    {
\&       "class": "Artist",
\&       "ids": ["1", "3"],
\&       "fetch": [ {
\&         "rel": "cds",
\&         "quantity": "all"
\&       } ]
\&     },
\&     {
\&       "class": "Producer",
\&       "ids": ["5"],
\&       "fetch": [ {
\&         "rel": "artists",
\&         "quantity": "2",
\&         "fetch": [ {
\&           "rel": "cds",
\&           "quantity": "all"
\&         } ]
\&       } ]
\&     }
\&   ]
\& }
.Ve
.PP
rules must be a hash keyed by class name.
.PP
"RULE ATTRIBUTES"
.SS includes
.IX Subsection "includes"
To prevent repetition between configs you can include other configs. For
example:
.PP
.Vb 9
\& {
\&   "sets": [ {
\&     "class": "Producer",
\&     "ids": ["5"]
\&   } ],
\&   "includes": [
\&     { "file": "base.json" }
\&   ]
\& }
.Ve
.PP
Includes must be an arrayref of hashrefs where the hashrefs have key 'file'
which is the name of another config file in the same directory. The original
config is merged with its includes using Hash::Merge.
.SS datetime_relative
.IX Subsection "datetime_relative"
Only available for MySQL and PostgreSQL at the moment, must be a value that
DateTime::Format::* can parse. For example:
.PP
.Vb 7
\& {
\&   "sets": [ {
\&     "class": "RecentItems",
\&     "ids": ["9"]
\&   } ],
\&   "datetime_relative": "2007\-10\-30 00:00:00"
\& }
.Ve
.PP
This will work when dumping from a MySQL database and will cause any datetime
fields (where datatype => 'datetime' in the column def of the schema class) to
be dumped as a DateTime::Duration object relative to the date specified in the
datetime_relative value. For example if the RecentItem object had a date field
set to 2007\-10\-25, then when the fixture is imported the field will be set to 5
days in the past relative to the current time.
.SS might_have
.IX Subsection "might_have"
Specifies whether to automatically dump might_have relationships. Should be a
hash with one attribute \- fetch. Set fetch to 1 or 0.
.PP
.Vb 10
\& {
\&   "might_have": { "fetch": 1 },
\&   "sets": [
\&     {
\&       "class": "Artist",
\&       "ids": ["1", "3"]
\&     },
\&     {
\&       "class": "Producer",
\&       "ids": ["5"]
\&     }
\&   ]
\& }
.Ve
.PP
Note: belongs_to rels are automatically dumped whether you like it or not, this
is to avoid FKs to nowhere when importing.  General rules on has_many rels are
not accepted at this top level, but you can turn them on for individual sets \-
see "SET ATTRIBUTES".
.SH "SET ATTRIBUTES"
.IX Header "SET ATTRIBUTES"
.SS class
.IX Subsection "class"
Required attribute. Specifies the DBIx::Class object class you wish to dump.
.SS ids
.IX Subsection "ids"
Array of primary key ids to fetch, basically causing an \f(CW$rs\fR\->find($_) for each.
If the id is not in the source db then it just won't get dumped, no warnings or
death.
.SS quantity
.IX Subsection "quantity"
Must be either an integer or the string 'all'. Specifying an integer will
effectively set the 'rows' attribute on the resultset clause, specifying 'all'
will cause the rows attribute to be left off and for all matching rows to be
dumped. There's no randomising here, it's just the first x rows.
.SS cond
.IX Subsection "cond"
A hash specifying the conditions dumped objects must match. Essentially this is
a JSON representation of a DBIx::Class search clause. For example:
.PP
.Vb 7
\& {
\&   "sets": [{
\&     "class": "Artist",
\&     "quantiy": "all",
\&     "cond": { "name": "Dave" }
\&   }]
\& }
.Ve
.PP
This will dump all artists whose name is 'dave'. Essentially
\&\f(CW$artist_rs\fR\->search({ name => 'Dave' })\->all.
.PP
Sometimes in a search clause it's useful to use scalar refs to do things like:
.PP
.Vb 1
\& $artist_rs\->search({ no1_singles => \e\*(Aq> no1_albums\*(Aq })
.Ve
.PP
This could be specified in the cond hash like so:
.PP
.Vb 7
\& {
\&   "sets": [ {
\&     "class": "Artist",
\&     "quantiy": "all",
\&     "cond": { "no1_singles": "\e> no1_albums" }
\&   } ]
\& }
.Ve
.PP
So if the value starts with a backslash the value is made a scalar ref before
being passed to search.
.SS join
.IX Subsection "join"
An array of relationships to be used in the cond clause.
.PP
.Vb 8
\& {
\&   "sets": [ {
\&     "class": "Artist",
\&     "quantiy": "all",
\&     "cond": { "cds.position": { ">": 4 } },
\&     "join": ["cds"]
\&   } ]
\& }
.Ve
.PP
Fetch all artists who have cds with position greater than 4.
.SS fetch
.IX Subsection "fetch"
Must be an array of hashes. Specifies which rels to also dump. For example:
.PP
.Vb 11
\& {
\&   "sets": [ {
\&     "class": "Artist",
\&     "ids": ["1", "3"],
\&     "fetch": [ {
\&       "rel": "cds",
\&       "quantity": "3",
\&       "cond": { "position": "2" }
\&     } ]
\&   } ]
\& }
.Ve
.PP
Will cause the cds of artists 1 and 3 to be dumped where the cd position is 2.
.PP
Valid attributes are: 'rel', 'quantity', 'cond', 'has_many', 'might_have' and
\&'join'. rel is the name of the DBIx::Class rel to follow, the rest are the same
as in the set attributes. quantity is necessary for has_many relationships, but
not if using for belongs_to or might_have relationships.
.SS has_many
.IX Subsection "has_many"
Specifies whether to fetch has_many rels for this set. Must be a hash
containing keys fetch and quantity.
.PP
Set fetch to 1 if you want to fetch them, and quantity to either 'all' or an
integer.
.PP
Be careful here, dumping has_many rels can lead to a lot of data being dumped.
.SS might_have
.IX Subsection "might_have"
As with has_many but for might_have relationships. Quantity doesn't do anything
in this case.
.PP
This value will be inherited by all fetches in this set. This is not true for
the has_many attribute.
.SS external
.IX Subsection "external"
In some cases your database information might be keys to values in some sort of
external storage.  The classic example is you are using DBIx::Class::InflateColumn::FS
to store blob information on the filesystem.  In this case you may wish the ability
to backup your external storage in the same way your database data.  The "external"
attribute lets you specify a handler for this type of issue.  For example:
.PP
.Vb 12
\&    {
\&        "sets": [{
\&            "class": "Photo",
\&            "quantity": "all",
\&            "external": {
\&                "file": {
\&                    "class": "File",
\&                    "args": {"path":"_\|_ATTR(photo_dir)_\|_"}
\&                }
\&            }
\&        }]
\&    }
.Ve
.PP
This would use DBIx::Class::Fixtures::External::File to read from a directory
where the path to a file is specified by the \f(CW\*(C`file\*(C'\fR field of the \f(CW\*(C`Photo\*(C'\fR source.
We use the uninflated value of the field so you need to completely handle backup
and restore.  For the common case we provide  DBIx::Class::Fixtures::External::File
and you can create your own custom handlers by placing a '+' in the namespace:
.PP
.Vb 1
\&    "class": "+MyApp::Schema::SomeExternalStorage",
.Ve
.PP
Although if possible I'd love to get patches to add some of the other common
types (I imagine storage in MogileFS, Redis, etc or even Amazon might be popular.)
.PP
See DBIx::Class::Fixtures::External::File for the external handler interface.
.SH "RULE ATTRIBUTES"
.IX Header "RULE ATTRIBUTES"
.SS cond
.IX Subsection "cond"
Same as with "SET ATTRIBUTES"
.SS fetch
.IX Subsection "fetch"
Same as with "SET ATTRIBUTES"
.SS join
.IX Subsection "join"
Same as with "SET ATTRIBUTES"
.SS has_many
.IX Subsection "has_many"
Same as with "SET ATTRIBUTES"
.SS might_have
.IX Subsection "might_have"
Same as with "SET ATTRIBUTES"
.SH "RULE SUBSTITUTIONS"
.IX Header "RULE SUBSTITUTIONS"
You can provide the following substitution patterns for your rule values. An
example of this might be:
.PP
.Vb 6
\&    {
\&        "sets": [{
\&            "class": "Photo",
\&            "quantity": "_\|_ENV(NUMBER_PHOTOS_DUMPED)_\|_",
\&        }]
\&    }
.Ve
.SS ENV
.IX Subsection "ENV"
Provide a value from \f(CW%ENV\fR
.SS ATTR
.IX Subsection "ATTR"
Provide a value from "config_attrs"
.SS catfile
.IX Subsection "catfile"
Create the path to a file from a list
.SS catdir
.IX Subsection "catdir"
Create the path to a directory from a list
.SH METHODS
.IX Header "METHODS"
.SS new
.IX Subsection "new"
.IP "Arguments: \e%$attrs" 4
.IX Item "Arguments: %$attrs"
.PD 0
.ie n .IP "Return Value: $fixture_object" 4
.el .IP "Return Value: \f(CW$fixture_object\fR" 4
.IX Item "Return Value: $fixture_object"
.PD
.PP
Returns a new DBIx::Class::Fixture object. \f(CW%attrs\fR can have the following
parameters:
.IP config_dir: 4
.IX Item "config_dir:"
required. must contain a valid path to the directory in which your .json
configs reside.
.IP debug: 4
.IX Item "debug:"
determines whether to be verbose
.IP ignore_sql_errors: 4
.IX Item "ignore_sql_errors:"
ignore errors on import of DDL etc
.IP config_attrs 4
.IX Item "config_attrs"
A hash of information you can use to do replacements inside your configuration
sets.  For example, if your set looks like:
.Sp
.Vb 10
\&   {
\&     "sets": [ {
\&       "class": "Artist",
\&       "ids": ["1", "3"],
\&       "fetch": [ {
\&         "rel": "cds",
\&         "quantity": "_\|_ATTR(quantity)_\|_",
\&       } ]
\&     } ]
\&   }
\&
\&    my $fixtures = DBIx::Class::Fixtures\->new( {
\&      config_dir => \*(Aq/home/me/app/fixture_configs\*(Aq
\&      config_attrs => {
\&        quantity => 100,
\&      },
\&    });
.Ve
.Sp
You may wish to do this if you want to let whoever runs the dumps have a bit
more control
.PP
.Vb 3
\& my $fixtures = DBIx::Class::Fixtures\->new( {
\&   config_dir => \*(Aq/home/me/app/fixture_configs\*(Aq
\& } );
.Ve
.SS available_config_sets
.IX Subsection "available_config_sets"
Returns a list of all the config sets found in the "config_dir".  These will
be a list of the json based files containing dump rules.
.SS dump
.IX Subsection "dump"
.IP "Arguments: \e%$attrs" 4
.IX Item "Arguments: %$attrs"
.PD 0
.IP "Return Value: 1" 4
.IX Item "Return Value: 1"
.PD
.PP
.Vb 6
\& $fixtures\->dump({
\&   config => \*(Aqset_config.json\*(Aq, # config file to use. must be in the config
\&                                # directory specified in the constructor
\&   schema => $source_dbic_schema,
\&   directory => \*(Aq/home/me/app/fixtures\*(Aq # output directory
\& });
.Ve
.PP
or
.PP
.Vb 6
\& $fixtures\->dump({
\&   all => 1, # just dump everything that\*(Aqs in the schema
\&   schema => $source_dbic_schema,
\&   directory => \*(Aq/home/me/app/fixtures\*(Aq, # output directory
\&   #excludes => [ qw/Foo MyView/ ], # optionally exclude certain sources
\& });
.Ve
.PP
In this case objects will be dumped to subdirectories in the specified
directory. For example:
.PP
.Vb 3
\& /home/me/app/fixtures/artist/1.fix
\& /home/me/app/fixtures/artist/3.fix
\& /home/me/app/fixtures/producer/5.fix
.Ve
.PP
\&\f(CW\*(C`schema\*(C'\fR and \f(CW\*(C`directory\*(C'\fR are required attributes. also, one of \f(CW\*(C`config\*(C'\fR or \f(CW\*(C`all\*(C'\fR must
be specified.
.PP
The optional parameter \f(CW\*(C`excludes\*(C'\fR takes an array ref of source names and can be
used to exclude those sources when dumping the whole schema. This is useful if
you have views in there, since those do not need fixtures and will currently result
in an error when they are created and then used with \f(CW\*(C`populate\*(C'\fR.
.PP
Lastly, the \f(CW\*(C`config\*(C'\fR parameter can be a Perl HashRef instead of a file name.
If this form is used your HashRef should conform to the structure rules defined
for the JSON representations.
.SS dump_config_sets
.IX Subsection "dump_config_sets"
Works just like "dump" but instead of specifying a single json config set
located in "config_dir" we dump each set named in the \f(CW\*(C`configs\*(C'\fR parameter.
.PP
The parameters are the same as for "dump" except instead of a \f(CW\*(C`directory\*(C'\fR
parameter we have a \f(CW\*(C`directory_template\*(C'\fR which is a coderef expected to return
a scalar that is a root directory where we will do the actual dumping.  This
coderef get three arguments: \f(CW$self\fR, \f(CW$params\fR and \f(CW$set_name\fR.  For
example:
.PP
.Vb 8
\&    $fixture\->dump_all_config_sets({
\&      schema => $schema,
\&      configs => [qw/one.json other.json/],
\&      directory_template => sub {
\&        my ($fixture, $params, $set) = @_;
\&        return io\->catdir(\*(Aqvar\*(Aq, \*(Aqfixtures\*(Aq, $params\->{schema}\->version, $set);
\&      },
\&    });
.Ve
.SS dump_all_config_sets
.IX Subsection "dump_all_config_sets"
.Vb 5
\&    my %local_params = %$params;
\&    my $local_self = bless { %$self }, ref($self);
\&    $local_params{directory} = $directory_template\->($self, \e%local_params, $set);
\&    $local_params{config} = $set;
\&    $self\->dump(\e%local_params);
.Ve
.PP
Works just like "dump" but instead of specifying a single json config set
located in "config_dir" we dump each set in turn to the specified directory.
.PP
The parameters are the same as for "dump" except instead of a \f(CW\*(C`directory\*(C'\fR
parameter we have a \f(CW\*(C`directory_template\*(C'\fR which is a coderef expected to return
a scalar that is a root directory where we will do the actual dumping.  This
coderef get three arguments: \f(CW$self\fR, \f(CW$params\fR and \f(CW$set_name\fR.  For
example:
.PP
.Vb 7
\&    $fixture\->dump_all_config_sets({
\&      schema => $schema,
\&      directory_template => sub {
\&        my ($fixture, $params, $set) = @_;
\&        return io\->catdir(\*(Aqvar\*(Aq, \*(Aqfixtures\*(Aq, $params\->{schema}\->version, $set);
\&      },
\&    });
.Ve
.SS populate
.IX Subsection "populate"
.IP "Arguments: \e%$attrs" 4
.IX Item "Arguments: %$attrs"
.PD 0
.IP "Return Value: 1" 4
.IX Item "Return Value: 1"
.PD
.PP
.Vb 3
\& $fixtures\->populate( {
\&   # directory to look for fixtures in, as specified to dump
\&   directory => \*(Aq/home/me/app/fixtures\*(Aq,
\&
\&   # DDL to deploy
\&   ddl => \*(Aq/home/me/app/sql/ddl.sql\*(Aq,
\&
\&   # database to clear, deploy and then populate
\&   connection_details => [\*(Aqdbi:mysql:dbname=app_dev\*(Aq, \*(Aqme\*(Aq, \*(Aqpassword\*(Aq],
\&
\&   # DDL to deploy after populating records, ie. FK constraints
\&   post_ddl => \*(Aq/home/me/app/sql/post_ddl.sql\*(Aq,
\&
\&   # use CASCADE option when dropping tables
\&   cascade => 1,
\&
\&   # optional, set to 1 to run ddl but not populate
\&   no_populate => 0,
\&
\&   # optional, set to 1 to run each fixture through \->create rather than have
\&   # each $rs populated using $rs\->populate. Useful if you have overridden new() logic
\&   # that effects the value of column(s).
\&   use_create => 0,
\&
\&   # optional, same as use_create except with find_or_create.
\&   # Useful if you are populating a persistent data store.
\&   use_find_or_create => 0,
\&
\&   # Dont try to clean the database, just populate over whats there. Requires
\&   # schema option. Use this if you want to handle removing old data yourself
\&   # no_deploy => 1
\&   # schema => $schema
\& } );
.Ve
.PP
In this case the database app_dev will be cleared of all tables, then the
specified DDL deployed to it, then finally all fixtures found in
/home/me/app/fixtures will be added to it. populate will generate its own
DBIx::Class schema from the DDL rather than being passed one to use. This is
better as custom insert methods are avoided which can to get in the way. In
some cases you might not have a DDL, and so this method will eventually allow a
\&\f(CW$schema\fR object to be passed instead.
.PP
If needed, you can specify a post_ddl attribute which is a DDL to be applied
after all the fixtures have been added to the database. A good use of this
option would be to add foreign key constraints since databases like Postgresql
cannot disable foreign key checks.
.PP
If your tables have foreign key constraints you may want to use the cascade
attribute which will make the drop table functionality cascade, ie 'DROP TABLE
\&\f(CW$table\fR CASCADE'.
.PP
\&\f(CW\*(C`directory\*(C'\fR is a required attribute.
.PP
If you wish for DBIx::Class::Fixtures to clear the database for you pass in
\&\f(CW\*(C`dll\*(C'\fR (path to a DDL sql file) and \f(CW\*(C`connection_details\*(C'\fR (array ref  of DSN,
user and pass).
.PP
If you wish to deal with cleaning the schema yourself, then pass in a \f(CW\*(C`schema\*(C'\fR
attribute containing the connected schema you wish to operate on and set the
\&\f(CW\*(C`no_deploy\*(C'\fR attribute.
.SH AUTHOR
.IX Header "AUTHOR"
.Vb 1
\&  Luke Saunders <luke@shadowcatsystems.co.uk>
\&
\&  Initial development sponsored by and (c) Takkle, Inc. 2007
.Ve
.SH CONTRIBUTORS
.IX Header "CONTRIBUTORS"
.Vb 1
\&  Ash Berlin <ash@shadowcatsystems.co.uk>
\&
\&  Matt S. Trout <mst@shadowcatsystems.co.uk>
\&
\&  John Napiorkowski <jjnapiork@cpan.org>
\&
\&  Drew Taylor <taylor.andrew.j@gmail.com>
\&
\&  Frank Switalski <fswitalski@gmail.com>
\&
\&  Chris Akins <chris.hexx@gmail.com>
\&
\&  Tom Bloor <t.bloor@shadowcat.co.uk>
\&
\&  Samuel Kaufman <skaufman@cpan.org>
.Ve
.SH LICENSE
.IX Header "LICENSE"
.Vb 1
\&  This library is free software under the same license as perl itself
.Ve
