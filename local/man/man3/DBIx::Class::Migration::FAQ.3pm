.\" -*- mode: troff; coding: utf-8 -*-
.\" Automatically generated by Pod::Man 5.01 (Pod::Simple 3.43)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" \*(C` and \*(C' are quotes in nroff, nothing in troff, for use with C<>.
.ie n \{\
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{\
.    if \nF \{\
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{\
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\" ========================================================================
.\"
.IX Title "DBIx::Class::Migration::FAQ 3pm"
.TH DBIx::Class::Migration::FAQ 3pm 2020-06-02 "perl v5.38.2" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH NAME
DBIx::Class::Migration::FAQ \- Answers to Frequently Asked Questions
.SH "When I run the commandline, I see a lot of debugging output"
.IX Header "When I run the commandline, I see a lot of debugging output"
.Vb 10
\&    SV = IV(0x7fb4e24dc858) at 0x7fb4e24dc868
\&      REFCNT = 1
\&      FLAGS = (ROK,READONLY)
\&      RV = 0x7fb4e0b0ddf8
\&        SV = PVHV(0x7fb4e24c48a0) at 0x7fb4e0b0ddf8
\&          REFCNT = 1
\&          FLAGS = (OBJECT,SHAREKEYS)
\&          STASH = 0x7fb4e2174a80        "DBI::db"
\&          ARRAY = 0x0
\&          KEYS = 0
\&          FILL = 0
\&          MAX = 7
\&          RITER = \-1
.Ve
.PP
There's some debugging code somewhere in the DBIx::Class::DeploymentHandler
dependency chain.  We've looked and can't find it :(  A case of beer at the
next YAPC we meet at to whoever can figure it out.
.PP
Although if you see this, there's nothing wrong.  The command will work as in
the documentation.  The only issue is that if there's a lot of debugging scroll
by, you might need to page up in your terminal to catch any real error
messages.
.PP
\&\fBUPDATE\fR:  I recieved an email from a contributor who has code dived a bit
and possibly narrowed down the issue.  I thought to report that stuff here.
When SQLT::Parser::DBIx::Class attempts to serialize schemas that are connected
it trys to serialize the connect object information.  This doesn't play so nice
with the way the YAML serializer works, since it does try hard to serialize
objects.
.PP
\&\fBUPDATE\fR: This may be fixed in recent updates to the DBIC ecosystem.  If you
are seeing this try upgraded DBIC and SQLT and see if it goes away.
.PP
\&\fBUPDATE\fR:  You really should not be seeing this anymore, if you are, and you're
on the lastest DBIC and related, please let me know.
.SH Contributing
.IX Header "Contributing"
Contributing to the project is easy.  First you'd fork the project over at
Github (<https://github.com/jjn1056/DBIx\-Class\-Migration>), clone the repo
down to your work environment and install project dependencies:
.PP
.Vb 3
\&    cpanm Dist::Zilla
\&    (dzil authordeps; dzil listdeps) |
\&      (unset AUTHOR_TESTING RELEASE_TESTING; cpanm)
.Ve
.PP
You should first have a Modern Perl setup, including local::lib.  If you
need help installing Perl and getting started, please take a look at the
Learning Perl website: <http://learn.perl.org/installing/>
.PP
If Test::Postgresql58 fails to install, you are probably running with
parallel testing. Try this:
.PP
.Vb 2
\&    (unset AUTHOR_TESTING RELEASE_TESTING HARNESS_OPTIONS;
\&      cpanm Test::Postgresql58)
.Ve
.SH Dist::Zilla?
.IX Header "Dist::Zilla?"
I realize Dist::Zilla seems to invoke feelings on nearly religious vigor
(both for and against).  After considering the options I felt using it, but
carefully constraining the use of plugins to the default set was a better
option than what I've done on other projects, which is to have a custom wrapper
on top of Module::Install (you can peek at that if you want over here:
<https://github.com/jjn1056/Maker>).  I've decided I'd rather not
continue to spend my limited time dealing with dependency and installation
management tools, when there's a rational solution that many people already
embrace available. The only other option is to continue to build and maintain
code for this purpose that nobody else uses, and possibly nobody else
understands.
.PP
If a better option with equal or greater maturity and community acceptance
emerges, I'll entertain changing.
.PP
If the requirement of typing \f(CW\*(C`cpanm Dist::Zilla\*(C'\fR and using the \f(CW\*(C`dzil\*(C'\fR command
line tool for a limited number of build jobs prevents you from contributing,
I think you are unreasonably stubborn.
.PP
If you do contribute to the project, please be aware that I'm not likely to
accept patches that include significant changes to the way I'm using
Dist::Zilla, including using plugins to weave pod, automagically guess
dependencies and generate tests.  I'd prefer to stick to the most simple and
standard Perl practices for building and installing code for the present.
.SH "I don't want my database sandbox files in my source control repository"
.IX Header "I don't want my database sandbox files in my source control repository"
Having the database sandboxes automatically created in the \f(CW\*(C`share\*(C'\fR directory
is a nice feature, but can clutter your repository history.  You really don't
need that in the source control, since installing and controlling your database
is something each developer who checks out the project should do.
.PP
If you are using \f(CW\*(C`git\*(C'\fR you can modify your \f(CW\*(C`.gitignore\*(C'\fR.  If you sandbox is
\&\f(CW\*(C`share/myapp\-schema.db\*(C'\fR or (if you are using the mysql or postgresql sandboxes)
\&\f(CW\*(C`share/myapp\-schema/\*(C'\fR you can add these lines to your \f(CW\*(C`.gitignore\*(C'\fR
.PP
.Vb 2
\&    share/musicbase\-schema/*
\&    share/musicbase\-schema.db
.Ve
.PP
Other source control systems have similiar approaches (recipes welcome for
sharing).
.SH "What's the command to run migrations on an existing database?"
.IX Header "What's the command to run migrations on an existing database?"
.Vb 4
\&    dbic\-migration \-Ilib status \e
\&      \-\-dsn="DBI:mysql:database=test;host=127.0.0.1;port=5142" \e
\&      \-\-user msandbox \e
\&      \-\-password msandbox
.Ve
.PP
Would be the general approach.
.SH "Error: Trouble creating a MySQL Sandbox when running AppArmor"
.IX Header "Error: Trouble creating a MySQL Sandbox when running AppArmor"
Its been reported that the developer database sandboxing feature doens't
work properly when using AppArmor.  I guess AppArmor considers this a
security violation.  Currently I don't have a reported workaround other than
to just disable AppArmor, which for developer level machines may or may not
be a problem.
.PP
Here's some symptoms of this problem, if you think you may be having it:
.PP
In \f(CW\*(C`/var/log/syslog\*(C'\fR something like:
.PP
.Vb 3
\&    kernel: [18593519.090601] type=1503 audit(1281847667.413:22):
\&    operation="inode_permission" requested_mask="::r" denied_mask="::r"
\&    fsuid=0 name="/etc/mysql0/my.cnf" pid=4884 profile="/usr/sbin/mysqld"
.Ve
.PP
If you need AppArmor, you'll have to setup and install MySQL the 'old school
way.'
.SH "Error: ""Failed to find share dir for dist..."""
.IX Header "Error: ""Failed to find share dir for dist..."""
You didn't specify a custom \f(CW\*(C`\-\-target_dir\*(C'\fR but forgot to make the \f(CW\*(C`/share\*(C'\fR
directory in your project application root.
.PP
By default we expect to find a \f(CW\*(C`/share\*(C'\fR directory in your primary project root
directory (contains your \f(CW\*(C`Makefile.PL\*(C'\fR or \f(CW\*(C`dist.ini\*(C'\fR, and the \f(CW\*(C`lib\*(C'\fR and \f(CW\*(C`t\*(C'\fR
directories for example) where we will create migrations.  At this time we can't
automatically create this \f(CW\*(C`/share\*(C'\fR directory in the same way we can create all
the migration files and directory for you.  You need to create that directory
yourself:
.PP
.Vb 1
\&    mkdir share
.Ve
.PP
Patches to fix this, or suggestions welcomed.
.SH "How to run a Migration Script before changing the Schema"
.IX Header "How to run a Migration Script before changing the Schema"
If you need to run a Migration Perl Script before the SQL Changes are applied
to your Database, you have to name your Upgrade Files properly.
.PP
.Vb 2
\&    share/migrations/_common/upgrade/5\-6/001_transform.pl
\&    share/migrations/MySQL/upgrade/5\-6/002_auto.sql
.Ve
.PP
Migration will run the upgrades by the Numbers, no matter in which Upgrade Folder
they are specified.
.SH "Can I use this even if I don't want to use DBIx::Class?"
.IX Header "Can I use this even if I don't want to use DBIx::Class?"
Not everyone loves using an ORM.  Personally I've found DBIx::Class to be
the only ORM that gets enough out of my way that I prefer it over plain SQL,
and I highly recommend you give it a go.  However if you don't want to, or can
not convince your fellow programers (yet :) ), here's one way to still use this
migrations and fixtures system.  Strictly speaking, we are still using
DBIx::Class behind the scenes, just you don't have to know about it or
use it.
.PP
You use a subclass of DBIx::Class::Schema::Loader in a namespace for your
application, like:
.PP
.Vb 1
\&    package MyApp::Schema;
\&
\&    use strict;
\&    use warnings;
\&
\&    use base \*(AqDBIx::Class::Schema::Loader\*(Aq;
\&
\&    our $VERSION = 1;
\&
\&    _\|_PACKAGE_\|_\->naming(\*(Aqcurrent\*(Aq);
\&    _\|_PACKAGE_\|_\->use_namespaces(1);
\&    _\|_PACKAGE_\|_\->loader_options( );
\&
\&    1;
.Ve
.PP
You'd put that in \f(CW\*(C`lib/MyApp/Schema.pm\*(C'\fR along with your other application code.
then just use \f(CW\*(C`MyApp::Schema\*(C'\fR as is discussed in the documentation.  This will
dynamically build a schema for you, as long as you set the schema arguments to
connect to your actual database.  Then everytime someone changes the database
you just up the \f(CW$VERSION\fR and take it from there.  Obviously this is a bit
more manual effort, but at least you can have the ability to populate to any
given version, manage fixtures, do some sane testing, etc.  Maybe you'll even
be able to convince people to try out DBIx::Class!
.PP
By the way, if you wanted, you can always dump the generated version of your
classes using \f(CW\*(C`make_schema\*(C'\fR (see "make_schema" in DBIx::Class::Migration and
"make_schema" in DBIx::Class::Migration::Script).
.SH "I am using MySQL and when the migration fails, it doesn't ROLLBACK"
.IX Header "I am using MySQL and when the migration fails, it doesn't ROLLBACK"
That's because MySQL does not support transaction DDL.  Even if you have a
transaction, MySQL will silently COMMIT when it bumps into some DDL.
.SH "I need to dump fixtures from a existing database"
.IX Header "I need to dump fixtures from a existing database"
You don't always have the luxury of building a new database from the start.
For example, you may have an existing database that you want to start to
create migrations for.  In this case you probably want to dump some data
directly from that existing database in order to create fixtures for testing
or for seeding a new database.
.PP
DBIx::Class::Migration will let you run the \f(CW\*(C`dump_all_sets\*(C'\fR and \f(CW\*(C`dump_named_sets\*(C'\fR
commands against an unversioned database.  For example:
.PP
.Vb 4
\&    dbic\-migration \-Ilib \-SMyApp::Schema dump_all_sets /
\&      \-\-dsn="dbi:mysql:database=myapp;host=10.0.88.98;port=3306" /
\&      \-\-username johnn /
\&      \-\-password $PASSWORD
.Ve
.PP
In this case let's say "dbi:mysql:database=myapp;host=10.0.88.98;port=3306" is
a database that you've been managing manually and it has some data that is useful
for creating your fixture sets.
.PP
When you run these commands against an unversioned database you will be warned
because we have no way of being sure what version of the fixture sets you should
be dumping.  We will just assume that whatever the Schema version is, is correct.
This can of course lead to bad or undumpable fixtures should your Schema and the
unversioned DB not match properly.  Buyer beware!
.SH "How do I specify the character set for a database or table?"
.IX Header "How do I specify the character set for a database or table?"
.SS MySQL
.IX Subsection "MySQL"
Specifying the default character set for the whole database should be done when
initially creating the database, which is outside the scope of
DBIx::Class::Migration. Remember that the default character set of the whole
database will still show in the properties of individual tables if the table
does not have its own specified.
.PP
To specify the character set of an individual table, use sqlt_deploy_hook {} in
the DBIC result source:
.PP
.Vb 4
\&  sub sqlt_deploy_hook {
\&    my ($self, $sqlt_table) = @_;
\&    $sqlt_table\->options({\*(AqDEFAULT CHARACTER SET\*(Aq => \*(Aqutf8\*(Aq});
\&  }
.Ve
.SH "Error: ""`' is not a module name"""
.IX Header "Error: ""`' is not a module name"""
Sorry this error is vague and I am working on a fix.  You will get this if you
have failed to provide a \f(CW\*(C`schema_class\*(C'\fR, either by setting it with the \-S or
\&\-schema_class commandline option flag:
.PP
.Vb 2
\&    dbic\-migration \-Ilib \-SMyApp::Schema
\&    dbic\-migration \-Ilib \-\-schema_class MyApp::Schema
.Ve
.PP
or by exporting the \f(CW%ENV:\fR
.PP
.Vb 1
\&    export DBIC_MIGRATION_SCHEMA_CLASS=MyApp::Schema
.Ve
.PP
Or, if you have a custom version of DBIx::Class::Migration::Script as
discussed in the tutorial, you are not providing a good \f(CW\*(C`schema_class\*(C'\fR value.
.SH "Error: ""Attribute (schema_class) does not pass the type constraint"""
.IX Header "Error: ""Attribute (schema_class) does not pass the type constraint"""
You probably forgot to include your project \f(CW\*(C`lib\*(C'\fR directory in the Perl search
path.  The easiest way to fix this is to use the \f(CW\*(C`I\*(C'\fR or \f(CW\*(C`lib\*(C'\fR command line:
option flag:
.PP
.Vb 1
\&    dbic\-migration \-Ilib \-SMyApp::Schema [command]
.Ve
.SH "When using the Postgresql Sandbox, I get ""FATAL: could not create shared memory segment"""
.IX Header "When using the Postgresql Sandbox, I get ""FATAL: could not create shared memory segment"""
There will be more like this:
.PP
.Vb 8
\&    FATAL:  could not create shared memory segment: Cannot allocate memory
\&    DETAIL:  Failed system call was shmget(key=1, size=2138112, 03600).
\&    HINT:  This error usually means that PostgreSQL\*(Aqs request for a shared memory
\&    segment exceeded available memory or swap space, or exceeded your kernel\*(Aqs
\&    SHMALL parameter.  You can either reduce the request size or reconfigure
\&    the kernel with larger SHMALL.  To reduce the request size (currently 2138112
\&    bytes), reduce PostgreSQL\*(Aqs shared memory usage, perhaps by reducing
\&    shared_buffers or max_connections.
.Ve
.PP
The solution is as presented.  Since I prefer not to change my system settings
permanently, just add the following to a little bash script in my application
.PP
.Vb 2
\&    sudo sysctl \-w kern.sysv.shmall=65536
\&    sudo sysctl \-w kern.sysv.shmmax=16777216
.Ve
.PP
I don't know enough about Postgresql to know if the above settings are good,
but they work for my testing.  Corrections very welcome!  Ideally I'd try to
find a way to offer a patch to Test::Postgresql58, although this seems to be
limited to people using Macs.
.SH "How to Release"
.IX Header "How to Release"
Here's the release steps I currently use, should I eventually find willing
comainters:
.IP "Update Version" 4
.IX Item "Update Version"
You need to increment the version in \f(CW\*(C`dist.ini\*(C'\fR and in DBIx::Class::Migration
.IP "Prepare Changes file" 4
.IX Item "Prepare Changes file"
Update the \f(CW\*(C`Changes\*(C'\fR file.  It would be ideal to have been adding to this as
you've gone along, but you should double check.
.IP "Update Author's list" 4
.IX Item "Update Author's list"
If there have been new contributors, be sure to give credit
.IP "Rebuild the README" 4
.IX Item "Rebuild the README"
.Vb 1
\&    pod2markdown < lib/DBIx/Class/Migration.pm > README.mkdn
.Ve
.Sp
This will make sure the \f(CW\*(C`README.mkdn\*(C'\fR file in the project root matches the most
recent updates.
.IP "Check your tests" 4
.IX Item "Check your tests"
.Vb 1
\&    AUTHOR_MODE=1 prove \-lvr t
.Ve
.IP "Update the repository" 4
.IX Item "Update the repository"
.Vb 3
\&    git add @stuff_to_add
\&    git commit \-m $message
\&    git push
.Ve
.IP "Make the Distribution" 4
.IX Item "Make the Distribution"
.Vb 2
\&    dzil release
\&    dzil clean
.Ve
.IP "Update the git version tag" 4
.IX Item "Update the git version tag"
I usually don't update and push the tag until we are on CPAN.
.Sp
.Vb 2
\&    git tag $VERSION \-m \*(Aqcpan release\*(Aq
\&    git push \-\-tags
.Ve
.SH AUTHOR
.IX Header "AUTHOR"
See DBIx::Class::Migration for author information
.SH "COPYRIGHT & LICENSE"
.IX Header "COPYRIGHT & LICENSE"
See DBIx::Class::Migration for copyright and license information
