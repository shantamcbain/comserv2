.\" -*- mode: troff; coding: utf-8 -*-
.\" Automatically generated by Pod::Man 5.01 (Pod::Simple 3.43)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" \*(C` and \*(C' are quotes in nroff, nothing in troff, for use with C<>.
.ie n \{\
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{\
.    if \nF \{\
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{\
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\" ========================================================================
.\"
.IX Title "DBIx::Class::Migration::Tutorial::FirstMigration 3pm"
.TH DBIx::Class::Migration::Tutorial::FirstMigration 3pm 2020-06-02 "perl v5.38.2" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH NAME
DBIx::Class::Migration::Tutorial::FirstMigration \- Prepare your first Migration
.SH GOAL
.IX Header "GOAL"
In this section you will use DBIx::Class::Migration to prepare migration
files for version 1.  You will also install a test database, create some 'seed'
data and dump some fixtures.
.PP
In preparation for this section, you might wish to revisit the documentation for
DBIx::Class::DeploymentHandler and in particular
DBIx::Class::DeploymentHandler::Manual::Intro
.SH "Using the dbic-migration commandline tool"
.IX Header "Using the dbic-migration commandline tool"
From your project home directory (that contains the \f(CW\*(C`dist.ini\*(C'\fR file) run the
\&\f(CW\*(C`dbic\-migration\*(C'\fR command line tool:
.PP
.Vb 1
\&    dbic\-migration version \-\-schema_class MusicBase::Schema \-Ilib
.Ve
.PP
This should return (something similar to):
.PP
.Vb 1
\&    Application version is 0.025
.Ve
.PP
Let's do a quick review.  \f(CW\*(C`dbic\-migration\*(C'\fR is your main gateway to managing
your migrations.  When using the tool you will give it one command (such as
\&\f(CW\*(C`version\*(C'\fR above) and any number of option flags (starting with \f(CW\*(C`\-\-\*(C'\fR or \f(CW\*(C`\-\*(C'\fR).
.PP
\&\fBNOTE:\fR The version reported might be different from the one mentioned in the
above documentation.  If you have a much older (or newer) version, please note
this tutorial was written against the one mentioned, and although I will strive
for backward compatibility feature sets might change.
.PP
When using the tool, you'll need to specify the \f(CW\*(C`schema_class\*(C'\fR that you are
creating and using migrations for.  Typically this will be your subclass of
DBIx::Class::Schema, and you'll need to extend the Perl module search path
with \f(CW\*(C`I\*(C'\fR as above.  This is so that \f(CW\*(C`perl\*(C'\fR will know about your custom application
libraries.
.PP
If you are going to be working with one schema for a bit, you can export
\&\f(CW\*(C`DBIC_MIGRATION_SCHEMA_CLASS\*(C'\fR into your current shell, that way you don't need
to keep retyping it.  If your shell is \f(CW\*(C`bash\*(C'\fR you can do this with the
following command:
.PP
.Vb 1
\&    export DBIC_MIGRATION_SCHEMA_CLASS=MusicBase::Schema
.Ve
.PP
Then you can simply do:
.PP
.Vb 1
\&    dbic\-migration \-Ilib version
.Ve
.PP
For the remainder of the tutorial, I will assume your Schema Class has been
exported.  Remember, you can always specific with the \f(CW\*(C`\-\-schema_class\*(C'\fR option
flag.
.PP
Before we move on, let's see the status of your schema and database:
.PP
.Vb 1
\&    dbic\-migration \-Ilib status
.Ve
.PP
This should return an error similar to the following:
.PP
.Vb 1
\&    Failed to find share dir for dist \*(AqMusicBase\-Schema\*(Aq at ....
.Ve
.PP
Why did this happen?  In order to use DBIx::Class::Migration you need to
tell it where to put the migration files.  You'd use the \f(CW\*(C`\-\-target_dir\*(C'\fR option
flag to do this, but if you don't provide a value, it will automatically
assume you have a \f(CW\*(C`share\*(C'\fR directory in the home directory of you application
and wish to put files there.  This is a good, accepted community practice for
storing non code data for your project and I recommend you follow it.  Let's
create the share directory and try again:
.PP
.Vb 2
\&    mkdir share
\&    dbic\-migration \-Ilib status
.Ve
.PP
You should now get:
.PP
.Vb 2
\&    Schema is 1
\&    Database is not currently installed
.Ve
.PP
Great!  Now you have the basics of using the commandline tool!
.SH "Prepare migration files"
.IX Header "Prepare migration files"
Let's create some migrations for Version 1 of your Schema.
.PP
.Vb 1
\&    dbic\-migration \-Ilib prepare
.Ve
.PP
You should see:
.PP
.Vb 2
\&    There is no current database deployed, so I can\*(Aqt prepare upgrades
\&    or downgrades
.Ve
.PP
\&\fBNOTE:\fR If you are getting some wild debugging messages, please see
DBIx::Class::Migration::FAQ for details.
.PP
Since this is the first version, we won't create any upgrade or downgrade
migrations.  Okay, lets see what we now have:
.PP
In your \f(CW\*(C`share\*(C'\fR directory you now have the following:
.PP
.Vb 10
\&    /share
\&      /fixtures
\&        /1
\&          /conf
\&            all_tables.json
\&      /migrations
\&        /_source  (There\*(Aqs stuff in here, but we won\*(Aqt peek!)
\&        /SQLite
\&          /deploy
\&            /1
\&              001\-auto\-_VERSION.sql
\&              001\-auto.sql
\&      musicbase\-schema.db
.Ve
.PP
So let's review.  We created a default fixture configuration that just serializes
all the database information.  This is probably not great for the long term but
until you get the hang of creating custom fixture configurations (and for this
you need to review DBIx::Class::Fixtures) it will serve.  In any case you
can take a quick peek to get the idea:
.PP
\&\f(CW\*(C`/share/fixtures/1/conf/all_tables.json\*(C'\fR
.PP
.Vb 10
\&    {
\&       "sets" : [
\&          {
\&             "quantity" : "all",
\&             "class" : "Cd"
\&          },
\&          {
\&             "quantity" : "all",
\&             "class" : "Track"
\&          },
\&          {
\&             "quantity" : "all",
\&             "class" : "Artist"
\&          }
\&       ],
\&       "might_have" : {
\&          "fetch" : 0
\&       },
\&       "belongs_to" : {
\&          "fetch" : 0
\&       },
\&       "has_many" : {
\&          "fetch" : 0
\&       }
\&    }
.Ve
.PP
DBIx::Class::Fixtures uses JSON for its configuration.  In this case you
can note that we are just dumping all the rows in all the tables.  You will see
that each time you prepare a version, we always build a fresh \f(CW\*(C`all_tables.json\*(C'\fR
for you to use as a default (in other words, don't change this one :) ).
.PP
You should also note that the path to your fixtures and your migrations contain
the schema version number you have prepared.  You'll see later that as you add
more schema versions this becomes your primary way of managing all the directories.
.PP
Three other files of interest have been created.  The first is 
\&\f(CW\*(C`001\-auto\-_VERSION.sql\*(C'\fR which is the DDL (data description language)  for the default 
database (SQLite) to create the meta table that DBIx::Class::DeploymentHandler 
uses to keep track of the version history for your deployments.  We also create a 
full DDL for the tables that make up your application.  In this case we have one table 
for each of the Artist, CD and Track Result classes.
.PP
\&\f(CW\*(C`/share/migrations/SQLite/deploy/1/001\-auto.sql\*(C'\fR
.PP
.Vb 10
\&    BEGIN TRANSACTION;
\&    \-\-
\&    \-\- Table: artist
\&    \-\-
\&    CREATE TABLE artist (
\&      artist_id INTEGER PRIMARY KEY NOT NULL,
\&      name varchar(96) NOT NULL
\&    );
\&    \-\-
\&    \-\- Table: cd
\&    \-\-
\&    CREATE TABLE cd (
\&      cd_id INTEGER PRIMARY KEY NOT NULL,
\&      artist_fk integer NOT NULL,
\&      title varchar(96) NOT NULL,
\&      FOREIGN KEY(artist_fk) REFERENCES artist(artist_id)
\&    );
\&    CREATE INDEX cd_idx_artist_fk ON cd (artist_fk);
\&    \-\-
\&    \-\- Table: track
\&    \-\-
\&    CREATE TABLE track (
\&      track_id INTEGER PRIMARY KEY NOT NULL,
\&      cd_fk integer NOT NULL,
\&      title varchar(96) NOT NULL,
\&      FOREIGN KEY(cd_fk) REFERENCES cd(cd_id)
\&    );
\&    CREATE INDEX track_idx_cd_fk ON track (cd_fk);
\&    COMMIT
.Ve
.PP
You should review this DDL to make sure it properly reflects your schema.
.PP
DBIx::Class::DeploymentHandler will build full DDL for each of the databases
you are creating migrations for.  We feel this is the best approach since it
lets you take maximum advantage of your target database.  By default, if you
don't specify a database (using the \f(CW\*(C`database\*(C'\fR option flag \- only needed
if you aren't doing the "default" thing; DBIx::Class::Migration
will figure out the right thing to do in nearly all circumstances)
we build migrations for SQLite, since that is easy to use and test,
but you can always build any of the supported databases. For example if
you ran the following:
.PP
.Vb 1
\&    dbic\-migration \-Ilib prepare \-\-database MySQL \-\-database SQLite
.Ve
.PP
We'd build migrations for both MySQL and SQLite. We'll try that later on, for
now let's stick to SQLite, since that is very low effort and you have plenty
to learn already!
.PP
There's one more file we've created \f(CW\*(C`musicbase\-schema.db\*(C'\fR which is an empty
SQLite database you can use for testing your migrations or for prototyping.
.PP
You've now completed creating your first migration!
.SH "Using a source control repository"
.IX Header "Using a source control repository"
If you are using a source control repository, like \f(CW\*(C`git\*(C'\fR, you probably want to
ignore checking in the Sqlite database file.  Ideally a new developer that
checks out the project should just install the database to the current version
rather than try to piggyback on your database.  This allows for better developer
level isolation.
.PP
In \f(CW\*(C`git\*(C'\fR you can add or modify \f(CW\*(C`.gitignore\*(C'\fR in your project directory:
.PP
.Vb 2
\&    share/musicbase\-schema/*
\&    share/musicbase\-schema.db
.Ve
.PP
This will ignore both SQLite databases and any Mysql or Postgresql sandboxes
you might create (as we will in a later section of the tutorial).
.SH "Customizing the Migration"
.IX Header "Customizing the Migration"
You have a database migration, but without any initial data it would be hard to
use.  Let's add some code to prepopulate the database with a few musicians and
cds.  That way when we install the database we can run some SQL on it and play
with it.  Generally when you are developing you are going to need to setup the
database with some useful data in order to be able to do some work.  Lets do
that now.  Perform the following commands in your shell:
.PP
.Vb 4
\&    mkdir share/migrations/_common
\&    mkdir share/migrations/_common/deploy
\&    mkdir share/migrations/_common/deploy/1
\&    touch share/migrations/_common/deploy/1/002\-demo.pl
.Ve
.PP
Then open the file \f(CW\*(C`share/migrations/_common/deploy/1/002\-demo.pl\*(C'\fR in your
editor of choice and add the following code:
.PP
.Vb 3
\&    use strict;
\&    use warnings;
\&    use DBIx::Class::Migration::RunScript;
\&
\&    migrate {
\&
\&      my $artist_rs = shift
\&        \->schema\->resultset(\*(AqArtist\*(Aq);
\&
\&      $artist_rs\->create({
\&        name =>\*(AqMichael Jackson\*(Aq,
\&        cds => [
\&          { title => \*(AqThriller\*(Aq, tracks => [
\&            { title => \*(AqBeat It\*(Aq },
\&            { title => \*(AqBillie Jean\*(Aq }],
\&          },
\&          { title => \*(AqBad\*(Aq, tracks => [
\&            { title => \*(AqDirty Diana\*(Aq },
\&            { title => \*(AqSmooth Criminal\*(Aq},
\&            { title => \*(AqLeave Me Alone\*(Aq }],
\&          },
\&        ]
\&      });
\&
\&      $artist_rs\->create({
\&        name =>\*(AqEminem\*(Aq,
\&        cds => [
\&          { title => \*(AqThe Marshall Mathers LP\*(Aq, tracks => [
\&            { title => \*(AqStan\*(Aq },
\&            { title => \*(AqThe Way I Am\*(Aq }],
\&          },
\&        ]});
\&
\&    };
.Ve
.PP
If you read the DBIx::Class::DeploymentHandler docs, you know that in
addition to running SQL files natively against your database of choice, you can
also create Perl run scripts, which is a Perl file that returns an anonymous
subroutine (similar to Plack).  That subroutine should expect to get one
argument from the deployment handler, which is a schema object upon which you
can run DBIx::Class commands.
.PP
\&\fBIMPORTANT\fR: The schema that is passed to your subroutine reference is one
that we autogenerate using DBIx::Class::Schema::Loader.  It is not the same
as your application subclass of DBIx::Class::Schema (for us that would be
MusicBase::Schema).  Since your schema is going to be in flux, we can't
rely on it for creating Perl run files.  Because of this, the names of the
relationships will reflect those that DBIx::Class::Schema::Loader generates
as part of its introspection of the database.  If you get confused and can't
figure out the generated schema, you can always dump it with the \f(CW\*(C`make_schema\*(C'\fR
command.
.PP
Why use Perl instead of SQL?  You should use what makes sense to you and what
you are comfortable with.  I use Perl when I can since I can put that in the
\&\f(CW\*(C`_common\*(C'\fR directory and use it for all the database I create migrations for.
That saves me a bit of repeating myself, but adds a bit of complexity to
understanding.
.PP
You should also notice that the file we created starts with '002'.  This ensures
that it will run after the '001' file (in this case we run \f(CW\*(C`001\-auto.sql\*(C'\fR
first.
.PP
Awesome, you now have customized your first migration.  Now we can install it!
.SS "Installing the migration"
.IX Subsection "Installing the migration"
Installing the migration is straightforward:
.PP
.Vb 1
\&    dbic\-migration \-Ilib install
.Ve
.PP
Lets take a peek at the database and make sure we got that demo data:
.PP
.Vb 1
\&    sqlite3 share/musicbase\-schema.db
.Ve
.PP
This should give us the SQLite shell, something like this:
.PP
.Vb 4
\&    SQLite version 3.7.5
\&    Enter ".help" for instructions
\&    Enter SQL statements terminated with a ";"
\&    sqlite>
.Ve
.PP
Enter this command
.PP
.Vb 1
\&    .tables
.Ve
.PP
You should see that your tables have been created:
.PP
.Vb 2
\&    artist               dbix_class_deploymenthandler_versions
\&    cd                   track
.Ve
.PP
Let's check the artist table.  We'd expect a few because of the
demo.pl script we wrote:
.PP
.Vb 1
\&    select * from artist;
.Ve
.PP
You should get:
.PP
.Vb 2
\&    1|Michael Jackson
\&    2|Eminem
.Ve
.PP
You've just verified your installation worked!  Exit the SQLite shell with
the \f(CW\*(C`.q\*(C'\fR command.
.SS "Make your first fixtures and test them."
.IX Subsection "Make your first fixtures and test them."
Next, lets dump some fixtures, that way you can mess around with the database
data as much as you'd like and then get back to a good, known state at any
time:
.PP
.Vb 1
\&    dbic\-migration \-Ilib dump_all_sets
.Ve
.PP
This will read each of the fixture configuration you've prepared, and
serialize them to \f(CW\*(C`/share/fixtures/1\*(C'\fR.  Since we just have the \f(CW\*(C`all_tables\*(C'\fR
fixture configuration, we'd only expect to see those.  Look at the directory
structure under share now:
.PP
.Vb 10
\&    /share
\&      /fixtures
\&        /1
\&          /all_tables
\&            _dumper_version
\&              /artist
\&                1.fix
\&                2.fix
\&              /cd
\&                (1\-3.fix)
\&              /track
\&                (1\-7.fix)
\&          /conf
\&            all_tables.json
\&      /migrations
\&        (...)
.Ve
.PP
For each fixture configuration you've created, you will get a directory and
serialized data.  Since this is the \f(CW\*(C`all_tables\*(C'\fR set, this represents all
the data in your database at the time your ran \f(CW\*(C`dump_all_sets\*(C'\fR.
.PP
Let's test the fixtures.  Pretend you've been developing on this database for
a while and you got a bunch of messy data around that you no longer need. Lets
clear out all the tables:
.PP
.Vb 1
\&    dbic\-migration \-Ilib delete_table_rows
.Ve
.PP
You should take care with this, and make sure you are not pointing to a
database you care about (such as Production) since this command loops through
all your tables and issues a \f(CW\*(C`delete\*(C'\fR.  If you have a lot of data, this
could take a bit of time.
.PP
Now you have tables but no data.  Lets restore the \f(CW\*(C`all_tables\*(C'\fR fixtures that
you previously dumped:
.PP
.Vb 1
\&    dbic\-migration \-Ilib populate
.Ve
.PP
Since we only have one fixture configuration, we can skip the step of specifying
which fixtures to load (you'd use the flag \f(CW\*(C`\-\-fixture_set\*(C'\fR to do that and you
can list as many as you wish).  You automatically restore the \f(CW\*(C`all_tables\*(C'\fR set
if you don't name one.  You'd expect to see some output like this:
.PP
.Vb 2
\&    Reading configurations from .../share/fixtures/1/conf
\&    Restored set all_tables to database
.Ve
.PP
Let's peek into the database and check:
.PP
.Vb 1
\&    sqlite3 share/musicbase\-schema.db
.Ve
.PP
and see if we have some tracks:
.PP
.Vb 8
\&    sqlite> select * from track;
\&    1|3|The Way I Am
\&    2|3|Stan
\&    3|1|Billie Jean
\&    4|2|Leave Me Alone
\&    5|2|Smooth Criminal
\&    6|1|Beat It
\&    7|2|Dirty Diana
.Ve
.PP
Perfect, you just restored your database to a given fixture dump!
.SH SUMMARY
.IX Header "SUMMARY"
You've just learned how to use the basics of the commandline \f(CW\*(C`dbic\-migration\*(C'\fR
to prepare and install migrations.  You also learned some basic customizing
of your migrations and you dumped and restore some fixtures.
.PP
At this point I'd say you have the minimum setup for being able to do real
database development.
.SH "NEXT STEPS"
.IX Header "NEXT STEPS"
Proceed to DBIx::Class::Migration::Tutorial::SecondMigration.
.SH AUTHOR
.IX Header "AUTHOR"
See DBIx::Class::Migration for author information
.SH "COPYRIGHT & LICENSE"
.IX Header "COPYRIGHT & LICENSE"
See DBIx::Class::Migration for copyright and license information
